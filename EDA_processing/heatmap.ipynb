{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция Влада\n",
    "def img_data_create(data, cat, im_path):\n",
    "    '''Функция, создающая словарь типа {image_id:{'image_size':...,'polygons':[[...],...,[...]],\n",
    "    'bboxes':[[...],...,[...]]},...} для категории cat, где image_id - id изображения, image_size - размер изображения,\n",
    "    polygons - массив координат для построения масок объектов на изображении, bboxes - массив ограничивающих рамок объектов на \n",
    "    изображении\n",
    "    Входные параметры: data - словарь с аннотациями для объектов\n",
    "                       cat - категория\n",
    "                       im_path - путь к изображениям\n",
    "    Выходные данные: словарь'''\n",
    "    cat_id = [x for x in data['categories'] if x['name'] == cat][0]['id']\n",
    "    anns = [ann for ann in data['annotations'] if ann['category_id'] == cat_id]\n",
    "    img_data = {}\n",
    "    for ann in anns:\n",
    "        img_data[ann['image_id']] = {}\n",
    "        img_data[ann['image_id']]['polygons'] = [] \n",
    "        img_data[ann['image_id']]['bboxes'] = [] \n",
    "    for ann in anns:\n",
    "        img_data[ann['image_id']]['polygons'].append(ann['segmentation'][0])\n",
    "        img_data[ann['image_id']]['bboxes'].append([ann['bbox'][0],ann['bbox'][1],ann['bbox'][0]+ann['bbox'][2]-1,ann['bbox'][1]+ann['bbox'][3]-1])\n",
    "    for im_id in tqdm(img_data):\n",
    "        im_fn = [x for x in data['images'] if x['id'] == im_id][0]['seg_file_name']\n",
    "        im = Image.open(f'{im_path}/{im_fn}')\n",
    "        img_data[im_id]['img_size']=im.size\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories:  ['storage_tank', 'Large_Vehicle', 'Small_Vehicle', 'plane', 'ship', 'Swimming_pool', 'Harbor', 'tennis_court', 'Ground_Track_Field', 'Soccer_ball_field', 'baseball_diamond', 'Bridge', 'basketball_court', 'Roundabout', 'Helicopter']\n"
     ]
    }
   ],
   "source": [
    "with open('iSAID_train.json', 'r', encoding='Utf-8') as json_data:\n",
    "    tmd=json.load(json_data)\n",
    "\n",
    "categories = list() \n",
    "for i in range(0, 15):\n",
    "    categories.append(tmd['categories'][i]['name'])\n",
    "print('categories: ', categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:00<00:00, 1154.78it/s]\n",
      "100%|██████████| 770/770 [00:00<00:00, 1658.12it/s]\n",
      "100%|██████████| 1099/1099 [00:00<00:00, 2754.52it/s]\n",
      "100%|██████████| 198/198 [00:00<00:00, 4214.46it/s]\n",
      "100%|██████████| 434/434 [00:00<00:00, 3102.63it/s]\n",
      "100%|██████████| 259/259 [00:00<00:00, 5667.42it/s]\n",
      "100%|██████████| 339/339 [00:00<00:00, 5700.63it/s]\n",
      "100%|██████████| 310/310 [00:00<00:00, 4542.91it/s]\n",
      "100%|██████████| 197/197 [00:00<00:00, 4080.00it/s]\n",
      "100%|██████████| 184/184 [00:00<00:00, 5158.42it/s]\n",
      "100%|██████████| 146/146 [00:00<00:00, 4983.95it/s]\n",
      "100%|██████████| 225/225 [00:00<00:00, 4849.45it/s]\n",
      "100%|██████████| 119/119 [00:00<00:00, 5658.02it/s]\n",
      "100%|██████████| 182/182 [00:00<00:00, 5171.49it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 4546.54it/s]\n"
     ]
    }
   ],
   "source": [
    "train_img_data = dict.fromkeys(categories)\n",
    "\n",
    "im_path = 'train/Semantic_masks/images/images'\n",
    "\n",
    "for cat in categories: \n",
    "    train_img_data[cat] = img_data_create(tmd, cat, im_path)\n",
    "\n",
    "for cat in categories:\n",
    "    for key in train_img_data[cat].keys(): \n",
    "        train_img_data[cat][key]['seg_file_name'] = 'train/Semantic_masks/images/images/' + tmd['images'][key]['seg_file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(train_img_data, category, target_size=(2400, 2400), save_figure=True):\n",
    "    \"\"\"\n",
    "    Generates a heatmap based on semantic masks and bounding boxes of images for a specified category.\n",
    "\n",
    "    Parameters:\n",
    "    - train_img_data: Dictionary containing image data.\n",
    "    - category: Category for generating the heatmap.\n",
    "    - target_size: Target size for the images.\n",
    "    \"\"\"\n",
    "    category_data = train_img_data[category]\n",
    "\n",
    "    filename = 'eda_images/heatmaps/' + category + '_HeatMap.png'\n",
    "\n",
    "    combined_mask = np.zeros(target_size, dtype=np.float64)\n",
    "\n",
    "    for image_id, image_info in category_data.items():\n",
    "        mask_filename = image_info['seg_file_name']\n",
    "        mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "\n",
    "        img_size = mask.shape\n",
    "        # img_size = image_info['img_size']\n",
    "\n",
    "        img_resized = cv2.resize(mask, target_size[::-1])\n",
    "        mask_resized = cv2.resize(mask, target_size[::-1])\n",
    "\n",
    "        bboxes = image_info['bboxes']\n",
    "\n",
    "        normalized_bboxes = [\n",
    "            (bbox[0] * target_size[1] / img_size[1],\n",
    "             bbox[1] * target_size[0] / img_size[0],\n",
    "             bbox[2] * target_size[1] / img_size[1],\n",
    "             bbox[3] * target_size[0] / img_size[0])\n",
    "            for bbox in bboxes\n",
    "        ]\n",
    "\n",
    "        for bbox in normalized_bboxes:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            x1 = int(x1 * target_size[1] / img_size[1])\n",
    "            y1 = int(y1 * target_size[0] / img_size[0])\n",
    "            x2 = int(x2 * target_size[1] / img_size[1])\n",
    "            y2 = int(y2 * target_size[0] / img_size[0])\n",
    "            combined_mask[y1:y2, x1:x2] += mask_resized[y1:y2, x1:x2]\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.imshow(combined_mask, cmap='viridis', alpha=1.0, interpolation='sinc')\n",
    "    plt.title(f\"Heatmap for Category: {category}\")\n",
    "    plt.xlabel(\"Width\")\n",
    "    plt.ylabel(\"Height\")\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('Intensity')\n",
    "\n",
    "    if save_figure:\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [09:10<00:00, 36.68s/it]\n"
     ]
    }
   ],
   "source": [
    "image_names = list()\n",
    "for cat in tqdm(categories): \n",
    "    plot_heatmap(train_img_data, cat, save_figure=True)\n",
    "    image_names.append('eda_images/heatmaps/' + cat + '_HeatMap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgages = [cv2.imread(f'{name}') for name in image_names]\n",
    "\n",
    "image_height, image_width, _ = imgages[0].shape\n",
    "canvas = np.zeros((5 * image_height, 3 * image_width, 3), dtype=np.uint8)\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        idx = i * 3 + j\n",
    "        if idx < len(imgages):\n",
    "            canvas[i * image_height: (i + 1) * image_height, j * image_width: (j + 1) * image_width, :] = imgages[idx]\n",
    "\n",
    "cv2.imwrite('eda_images/heatmaps/Total_heat_map.png', canvas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
